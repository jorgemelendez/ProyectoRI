<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Redes neuronales artificiales en la estimación de la evapotranspiración de referencia</title><link xmlns="" rel="canonical" href="http://www.scielo.org.mx/scielo.php?script=sci_arttext&amp;pid=S2007-09342011000300010">
<meta xmlns="" http-equiv="Pragma" content="no-cache">
<meta xmlns="" http-equiv="Expires" content="Mon, 06 Jan 1990 00:00:01 GMT">
<meta xmlns="" Content-math-Type="text/mathml">
<meta xmlns="" name="citation_journal_title" content="Revista mexicana de ciencias agrícolas">
<meta xmlns="" name="citation_journal_title_abbrev" content="Rev. Mex. Cienc. Agríc">
<meta xmlns="" name="citation_publisher" content="Instituto Nacional de Investigaciones Forestales, Agrícolas y Pecuarias">
<meta xmlns="" name="citation_title" content="Redes neuronales artificiales en la estimación de la evapotranspiración de referencia">
<meta xmlns="" name="citation_date" content="06/2011">
<meta xmlns="" name="citation_volume" content="2">
<meta xmlns="" name="citation_issue" content="3">
<meta xmlns="" name="citation_issn" content="2007-0934">
<meta xmlns="" name="citation_doi" content="">
<meta xmlns="" name="citation_abstract_html_url" content="http://www.scielo.org.mx/scielo.php?script=sci_abstract&amp;pid=S2007-09342011000300010&amp;lng=es&amp;nrm=iso&amp;tlng=es">
<meta xmlns="" name="citation_fulltext_html_url" content="http://www.scielo.org.mx/scielo.php?script=sci_arttext&amp;pid=S2007-09342011000300010&amp;lng=es&amp;nrm=iso&amp;tlng=es">
<meta name="citation_author" content="Cervantes-Osornio, Rocío">
<meta name="citation_author_institution" content="Universidad Autónoma Chapingo, Texcoco">
<meta name="citation_author" content="Arteaga-Ramírez, Ramón">
<meta name="citation_author_institution" content="Universidad Autónoma Chapingo, Texcoco">
<meta name="citation_author" content="Vázquez-Peña, Mario Alberto">
<meta name="citation_author_institution" content="Universidad Autónoma Chapingo, Texcoco">
<meta name="citation_author" content="Quevedo-Nolasco, Abel">
<meta name="citation_author_institution" content="Colegio de Posgraduados, Texcoco">
<meta xmlns="" name="citation_firstpage" content="433">
<meta xmlns="" name="citation_lastpage" content="447">
<meta xmlns="" name="citation_id" content="">
<meta xmlns="" name="citation_pdf_url" language="es" default="true" content="http://www.scielo.org.mx/pdf/remexca/v2n3/v2n3a10.pdf">
<link xmlns="" rel="stylesheet" type="text/css" href="/css/screen.css">
<script xmlns="" language="javascript" src="applications/scielo-org/js/jquery-1.4.2.min.js"></script><script xmlns="" language="javascript" src="applications/scielo-org/js/toolbox.js"></script></head><body><a name="top"></a><div class="container"><div class="top"><div id="issues"></div><TABLE xmlns="" cellSpacing="0" cellPadding="7" width="100%" border="0"><TBODY><TR>
<TD vAlign="top" width="26%"><P align="center">
<A href="http://www.scielo.org.mx/scielo.php?lng=es"><IMG src="/img/es/fbpelogp.gif" border="0" alt="SciELO - Scientific Electronic Library Online"></A><BR>
</P></TD>
<TD vAlign="top" width="74%"><TABLE><TBODY><TR>
<TD NoWrap>
<IMG src="/img/es/grp1c.gif"> <IMG src="/img/es/artsrc.gif"><BR><A href="http://www.scielo.org.mx/scielo.php?script=sci_issuetoc&amp;pid=2007-093420110003&amp;lng=es&amp;nrm=iso"><IMG src="/img/es/toc.gif" border="0" alt="vol.2 número3"></A><A href="http://www.scielo.org.mx/scielo.php?script=sci_arttext&amp;pid=S2007-09342011000300009&amp;lng=es&amp;nrm=iso"><IMG src="/img/es/prev.gif" border="0" alt="Biofertilización de café orgánico en etapa de vivero en Chiapas, México"></A><A href="http://www.scielo.org.mx/scielo.php?script=sci_arttext&amp;pid=S2007-09342011000300011&amp;lng=es&amp;nrm=iso"><IMG src="/img/es/next.gif" border="0" alt="Efectos de condición del fruto y temperatura de almacenamiento en la calidad de granada roja"></A> <A href="http://www.scielo.org.mx/cgi-bin/wxis.exe/iah/?IsisScript=iah/iah.xis&amp;base=article%5Edremexca&amp;index=AU&amp;format=iso.pft&amp;lang=e&amp;limit=2007-0934"><IMG src="/img/es/author.gif" border="0" alt="índice de autores"></A><A href="http://www.scielo.org.mx/cgi-bin/wxis.exe/iah/?IsisScript=iah/iah.xis&amp;base=article%5Edremexca&amp;index=KW&amp;format=iso.pft&amp;lang=e&amp;limit=2007-0934"><IMG src="/img/es/subject.gif" border="0" alt="índice de materia"></A><A href="http://www.scielo.org.mx/cgi-bin/wxis.exe/iah/?IsisScript=iah/iah.xis&amp;base=article%5Edremexca&amp;format=iso.pft&amp;lang=e&amp;limit=2007-0934"><IMG src="/img/es/search.gif" border="0" alt="búsqueda de artículos"></A>
</TD>
<TD noWrap valign="bottom">
<A href="http://www.scielo.org.mx/scielo.php?script=sci_serial&amp;pid=2007-0934&amp;lng=es&amp;nrm=iso"><IMG src="/img/es/home.gif" border="0" alt="Home Page"></A><A href="http://www.scielo.org.mx/scielo.php?script=sci_alphabetic&amp;lng=es&amp;nrm=iso"><IMG src="/img/es/alpha.gif" border="0" alt="lista alfabética de revistas"></A>
              
            </TD>
</TR></TBODY></TABLE></TD>
</TR></TBODY></TABLE>
<BR xmlns=""></div><div class="content"><form xmlns="" name="addToShelf" method="post" action="http://www.scielo.org/applications/scielo-org/services/addArticleToShelf.php" target="mensagem">
<input type="hidden" name="PID" value="S2007-09342011000300010"><input type="hidden" name="url" value="http://www.scielo.org.mx/scielo.php?script=sci_arttext%26pid=S2007-09342011000300010%26lng=es%26nrm=iso%26tlng=es">
</form>
<form xmlns="" name="citedAlert" method="post" action="http://www.scielo.org/applications/scielo-org/services/citedAlert.php" target="mensagem">
<input type="hidden" name="PID" value="S2007-09342011000300010"><input type="hidden" name="url" value="http://www.scielo.org.mx/scielo.php?script=sci_arttext%26pid=S2007-09342011000300010%26lng=es%26nrm=iso%26tlng=es">
</form>
<form xmlns="" name="accessAlert" method="post" action="http://www.scielo.org/applications/scielo-org/services/accessAlert.php" target="mensagem">
<input type="hidden" name="PID" value="S2007-09342011000300010"><input type="hidden" name="url" value="http://www.scielo.org.mx/scielo.php?script=sci_arttext%26pid=S2007-09342011000300010%26lng=es%26nrm=iso%26tlng=es">
</form>
<div xmlns="" id="group">
<div id="toolBox">
<h2 id="toolsSection">Servicios Personalizados</h2>
<div class="toolBoxSection"><h2 class="toolBoxSectionh2">Revista</h2></div>
<div class="box">
<ul>
<li>
<img src="/img/es/iconStatistics.gif"><a href="http://analytics.scielo.org/?journal=2007-0934&amp;collection=mex" target="_blank">SciELO Analytics</a>
</li>
<li id="google_metrics_link_li" style="display: none;">
<img src="/img/es/iconStatistics.gif"><a id="google_metrics_link" target="_blank">Google Scholar H5M5 (<span id="google_metrics_year"></span>)</a>
</li>
</ul>
<script type="text/javascript"> 
              $(document).ready(function() {
                  var url =  "/google_metrics/get_h5_m5.php?issn=2007-0934&callback=?";
                  $.getJSON(url,  function(data) {
                      $("#google_metrics_year").html(data['year']);
                      $('#google_metrics_link').attr('href', data['url']);
                      $("#google_metrics_link_li").show();
                  });
              });
            </script>
</div>
<div class="toolBoxSection"><h2 class="toolBoxSectionh2">Articulo</h2></div>
<div class="box"><ul>
<li><a href="/pdf/remexca/v2n3/v2n3a10.pdf"><img src="/img/en/iconPDFDocument.gif">Español (pdf)
    </a></li>
<li><a href="http://www.scielo.org.mx/scieloOrg/php/articleXML.php?pid=S2007-09342011000300010&amp;lang=es" rel="nofollow" target="xml"><img src="/img/es/iconXMLDocument.gif">Artículo en XML</a></li>
<li><a href="javascript:%20void(0);" onClick="window.open('http://www.scielo.org.mx/scieloOrg/php/reference.php?pid=S2007-09342011000300010&amp;caller=www.scielo.org.mx&amp;lang=es','','width=640,height=480,resizable=yes,scrollbars=1,menubar=yes');
                        callUpdateArticleLog('referencias_do_artigo');" rel="nofollow"><img src="/img/es/iconReferences.gif">Referencias del artículo</a></li>
<li>
<td valign="middle"><a href="javascript:void(0);" onmouseout="status='';" class="nomodel" style="text-decoration: none;" onclick='OpenArticleInfoWindow ( 780, 450, "http://www.scielo.org.mx/scielo.php?script=sci_isoref&amp;pid=S2007-09342011000300010&amp;lng=es&amp;tlng=es"); ' rel="nofollow" onmouseover=" status='Como citar este artículo'; return true; "><img border="0" align="middle" src="/img/es/fulltxt.gif"></a></td>
<td><a href="javascript:void(0);" onmouseout="status='';" class="nomodel" style="text-decoration: none;" onclick='OpenArticleInfoWindow ( 780, 450, "http://www.scielo.org.mx/scielo.php?script=sci_isoref&amp;pid=S2007-09342011000300010&amp;lng=es&amp;tlng=es");' rel="nofollow" onmouseover=" status='Como citar este artículo'; return true; ">Como citar este artículo</a></td>
</li>
<li>
<img src="/img/es/iconStatistics.gif"><a href="http://analytics.scielo.org/?document=S2007-09342011000300010&amp;collection=mex" target="_blank">SciELO Analytics</a>
</li>
<script language="javascript" src="article.js"></script><li><a href="javascript:%20void(0);" onClick="window.open('http://www.scielo.org.mx/scieloOrg/php/translate.php?pid=S2007-09342011000300010&amp;caller=www.scielo.org.mx&amp;lang=es&amp;tlang=es&amp;script=sci_arttext','','width=640,height=480,resizable=yes,scrollbars=1,menubar=yes');
                        callUpdateArticleLog('referencias_do_artigo');" rel="nofollow"><img src="/img/es/iconTranslation.gif">Traducción automática</a></li>
<li><a href="javascript:void(0);" onclick="window.open('http://espejo.scielo.org.mx/applications/scielo-org/pages/services/sendMail.php?pid=S2007-09342011000300010&amp;caller=www.scielo.org.mx&amp;lang=es','','width=640,height=480,resizable=yes,scrollbars=1,menubar=yes,');" rel="nofollow"><img src="/img/es/iconEmail.gif">Enviar artículo por email</a></li>
</ul></div>
<div class="toolBoxSection"><h2 class="toolBoxSectionh2">Indicadores</h2></div>
<div class="box"><ul>
<li>
<img src="/img/es/iconCitedOff.gif" alt="No hay artículos citados">Citado por SciELO </li>
<li>
<img src="/img/es/iconStatistics.gif"><a href="http://analytics.scielo.org/w/accesses?document=S2007-09342011000300010&amp;collection=mex" target="_blank">Accesos</a>
</li>
</ul></div>
<div class="toolBoxSection"><h2 class="toolBoxSectionh2">Links relacionados</h2></div>
<div class="box"><ul><li>
<img src="/img/es/iconRelatedOff.gif" alt="No hay artículos similares">Similares en
    SciELO </li></ul></div>
<div class="toolBoxSection"><h2 class="toolBoxSectionh2">Compartir</h2></div>
<div class="box"><ul>
<li>
<div class="addthis_toolbox addthis_default_style">
<a class="addthis_button_delicious"></a><a class="addthis_button_google"></a><a class="addthis_button_twitter"></a><a class="addthis_button_digg"></a><a class="addthis_button_citeulike"></a><a class="addthis_button_connotea"></a><a href="http://www.mendeley.com/import/?url=http://www.scielo.org.mx/scielo.php?script=sci_arttext%26pid=S2007-09342011000300010%26lng=es%26nrm=iso%26tlng=es" title="Mendeley"><img src="http://www.mendeley.com/graphics/mendeley.png"></a><a href="http://www.addthis.com/bookmark.php?v=250&amp;username=xa-4c347ee4422c56df" class="addthis_button_expanded">Otros</a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=xa-4c347ee4422c56df"></script>
</li>
<li><div class="addthis_toolbox addthis_default_style"><a href="http://www.addthis.com/bookmark.php?v=250&amp;username=xa-4c347ee4422c56df" class="addthis_button_expanded">Otros</a></div></li>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=xa-4c347ee4422c56df"></script>
</ul></div>
<hr>
<ul><li><a id="permalink" href="javascript:void(0);"><img src="/img/common/iconPermalink.gif">Permalink</a></li></ul>
</div>
<div id="permalink_box" style="margin-left:20px;background-color:#F2F2F2;border: 1px solid #CCC;display:none;position:absolute;z-index:1;padding:2px 10px 10px 10px;">
<div style="text-align:right;"><img src="/img/common/icon-close.png" onClick="$('#permalink_box').toggle();"></div>
<input type="text" name="short-url" id="short-url">
</div>
</div>
<h2 xmlns=""><a href="http://www.scielo.org.mx/scielo.php?script=sci_serial&amp;pid=2007-0934&amp;lng=es&amp;nrm=iso">Revista mexicana de ciencias agrícolas</a></h2>
<h2 xmlns="" id="printISSN">
<FONT color="#0000A0"><!--PRINTes--><em>versión impresa</em> ISSN </FONT>2007-0934</h2>
<h3 xmlns="">Rev. Mex. Cienc. Agríc vol.2 no.3 Texcoco may./jun. 2011</h3>
<h4 xmlns="" id="doi">  </h4>
<div xmlns="" class="index,es">
<!--version=html-->  	    <p align="justify"><font face="verdana" size="4">Ensayo</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="center"><font face="verdana" size="4"><b>Redes neuronales artificiales en la estimaci&oacute;n de la evapotranspiraci&oacute;n de referencia*</b></font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="center"><font face="verdana" size="3"><b>Artificial neural networks in the estimation of reference evapotranspiration</b></font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="center"><font face="verdana" size="2"><b>Roc&iacute;o Cervantes&#45;Osornio<sup>1</sup>, Ram&oacute;n Arteaga&#45;Ram&iacute;rez<sup>1</sup>, Mario Alberto V&aacute;zquez&#45;Pe&ntilde;a<sup>1</sup>, Waldo Ojeda&#45;Bustamante<sup>2</sup> y Abel Quevedo&#45;Nolasco<sup>3</sup></b></font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><sup>1</sup> <i>Posgrado en Ingenier&iacute;a Agr&iacute;cola y Uso Integral del Agua. Universidad Aut&oacute;noma Chapingo. Carretera M&eacute;xico&#45;Texcoco, km 38.5. Chapingo, Texcoco, Estado de M&eacute;xico. C. P. 56230</i>. (<a href="mailto:rartegar@taurus.chapingo.mx">rartegar@taurus.chapingo.mx</a>), (<a href="mailto:mvazquezp@correo.chapingo.mx">mvazquezp@correo.chapingo.mx</a>) <sup>&sect;</sup><i>Autora para correspondencia</i>: <a href="mailto:rcervantes@colpos.mx">rcervantes@colpos.mx</a>.</font></p>  	    <p align="justify"><font face="verdana" size="2"><sup>2</sup> <i>Instituto Mexicano de Tecnolog&iacute;a del Agua. Paseo Cuauhn&aacute;uac 8532, Col. Progreso, Jiutepec, Morelos. C. P. 62550</i>. (<a href="mailto:wojeda@tlaloc.imta.mx">wojeda@tlaloc.imta.mx</a>).</font></p>  	    <p align="justify"><font face="verdana" size="2"><sup>3</sup> <i>Colegio de Posgraduados. Carretera M&eacute;xico&#45;Texcoco, km 36.5. Montecillo, Texcoco, Estado de M&eacute;xico, C. P. 56230</i>. (<a href="mailto:anolasco@colpos.mx">anolasco@colpos.mx</a>).</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2">* Recibido: diciembre de 2010    <br> 	Aceptado: abril de 2011</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Resumen</b></font></p>  	    <p align="justify"><font face="verdana" size="2">Las redes neuronales artificiales representan un vasto campo de investigaci&oacute;n, puesto que han demostrado tener aplicaci&oacute;n en varios campos de la ciencia, su capacidad de lidiar con no linealidades en diversos fen&oacute;menos, y los diferentes trabajos realizados en la estimaci&oacute;n y/o pron&oacute;stico para predecir variables clim&aacute;ticas, que inciden directa e indirectamente en la evapotranspiraci&oacute;n de referencia y la propia evapotranspiraci&oacute;n ha originado el desarrollo de este trabajo. El objetivo fue presentar una revisi&oacute;n de literatura sobre redes neuronales artificiales, para la estimaci&oacute;n de la evapotranspiraci&oacute;n de referencia y variables relacionadas, que incluye: la teor&iacute;a y fundamentos de las redes neuronales artificiales y el algoritmo backpropagation; algunas similitudes y diferencias entre los modelos estad&iacute;sticos tradicionales y las redes neuronales artificiales; aplicaciones de las redes neuronales artificiales en la estimaci&oacute;n de la evapotranspiraci&oacute;n de referencia; y variables que se asocian con las perspectivas de las redes neuronales artificiales en la predicci&oacute;n de variables agroclim&aacute;ticas. Las redes neuronales artificiales est&aacute;ticas multicapa, son hasta ahora las m&aacute;s comunes en la estimaci&oacute;n de evapotranspiraci&oacute;n de referencia, y se vislumbra un cambio en la tendencia de aplicar redes neuronales artificiales de tipo din&aacute;mico.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Palabras clave:</b> modelos, predicci&oacute;n, variables meteorol&oacute;gicas.</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Abstract</b></font></p>  	    <p align="justify"><font face="verdana" size="2">Artificial neural networks represent a vast research field, since they have demonstrated application in various fields of science. Its ability to cope with nonlinearities in several different phenomena and work in the estimation or forecast meteorological variables, which act directly and indirectly in reference evapotranspiration and actual evapotranspiration, have led to this work development. The aim was to present a literature review on artificial neural networks for reference evapotranspiration estimating and related variables, including: theory and artificial neural networks foundations and backpropagation algorithm, some similarities and differences between traditional statistical models and artificial neural networks, applications of artificial neural networks in reference evapotranspiration estimating and variables associated with the prospects of artificial neural networks in agroclimatic variables prediction. Static neural multilayer networks, are so far the most common in reference evapotranspiration estimation and a change in applying artificial neural networks of dynamic type trend looms.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Key words:</b> modeling, meteorological variables, prediction.</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>INTRODUCCI&Oacute;N</b></font></p>  	    <p align="justify"><font face="verdana" size="2">La evapotranspiraci&oacute;n de referencia (ET<sub>0</sub>), se calcula con la ecuaci&oacute;n dada por Penman&#45;Monteith, modificada por la Organizaci&oacute;n de las Naciones Unidas para la Agricultura y la Alimentaci&oacute;n (FAO), de acuerdo a los lineamientos del bolet&iacute;n 56 de la FAO (Allen <i>et al</i>., 1998), para ello es necesario conocer la temperatura, la humedad relativa (variable dependiente de la presi&oacute;n real de vapor de agua), la radiaci&oacute;n global diaria, y la velocidad del viento. Sobreestimar la ET<sub>0</sub> resulta en p&eacute;rdidas de grandes cantidades de agua que repercuten en los rendimientos de los cultivos, y subestimarla redunda en estr&eacute;s h&iacute;drico para las plantas, por tanto se necesita conocer cu&aacute;nto regar. La idea central de calendarizar el riego es predecir cu&aacute;nto y cuando aplicar riego a los cultivos a lo largo de su ciclo fenol&oacute;gico, de aqu&iacute; la importancia de estimar la ET<sub>0</sub> con anticipaci&oacute;n para programar el agua que ser&aacute; distribuida en las zonas de riego.</font></p>  	    <p align="justify"><font face="verdana" size="2">El concepto de neurona artificial se introdujo en 1943, pero es hasta &uacute;ltimas fechas cuando ha florecido la investigaci&oacute;n en diversas aplicaciones debido a la introducci&oacute;n del algoritmo backpropagation feedforward (McCulloch and Pitts, 1943; Rumelhart <i>et al</i>., 1986; Maier y Dandy, 2000). El cerebro es una computadora, en el sentido de ser un sistema que procesa informaci&oacute;n, altamente compleja, no lineal y de procesamiento paralelo; este tiene la capacidad de organizar a las neuronas de tal forma para ejecutar ciertas tareas (reconocimiento de patrones, percepci&oacute;n, control motor) muchas veces m&aacute;s r&aacute;pidamente que la computadora digital m&aacute;s veloz en existencia (Haykin, 1994).</font></p>  	    <p align="justify"><font face="verdana" size="2">Zhang <i>et al</i>. (1998) definen a las redes neuronales artificiales (RNA) como m&eacute;todos manejadores de datos (cuando existen suficientes) adaptados por s&iacute; mismos, en el sentido de que existen pocas suposiciones a priori sobre el modelo del problema bajo estudio; las RNA aprenden de los ejemplos y capturan relaciones funcionales sutiles entre los datos, aun si las relaciones subyacentes no son conocidas o dif&iacute;ciles de describir, y a&ntilde;ade que en este sentido las RNA se tratan como un m&eacute;todo estad&iacute;stico multivariado no lineal y no param&eacute;trico. Estas caracter&iacute;sticas representan ventajas que colocan a las RNA como un m&eacute;todo de expectativa para predecir variables agroclim&aacute;ticas. Entre los trabajos realizados para estimar evapotranspiraci&oacute;n de referencia con RNA se encuentran a Wang <i>et al.</i> (2008) y Gonz&aacute;lez&#45;Camacho <i>et al.</i> (2008) que estiman la ET<sub>0</sub>, de igual forma, con una RNA feedforward backpropagation.</font></p>  	    <p align="justify"><font face="verdana" size="2">Entre los objetivos que se plantearon para el desarrollo del presente trabajo fueron: presentar la teor&iacute;a y fundamentos de las RNA multicapa con el algoritmo backpropagation; definir algunas similitudes y diferencias entre los modelos de series de tiempo, regresi&oacute;n lineal y las RNA; realizar una revisi&oacute;n de literatura de las aplicaciones de las RNA en la estimaci&oacute;n de la ET<sub>0</sub> y variables asociadas a &eacute;sta y determinar algunas de las perspectivas al futuro de las RNA en la predicci&oacute;n de variables meteorol&oacute;gicas.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Teor&iacute;a y fundamentos de las redes neuronales artificiales</b></font></p>  	    <p align="justify"><font face="verdana" size="2">Existen ciertos criterios que hay que definir en el proceso de aplicaci&oacute;n de un modelo de red neuronal artificial para estimar alguna variable climatol&oacute;gica. Dicho proceso empieza a especificar el problema, para redes supervisadas tal como la red feedforward entrenada con el algoritmo backpropagation, significa la elecci&oacute;n de un conjunto de vectores de entrada y un conjunto de vectores deseados de salida (Demuth <i>et al.,</i> 2008). Antes de entrenar la red se inicializan los pesos y sesgos al utilizar alg&uacute;n algoritmo, una vez hecho esto se est&aacute; listo para el entrenamiento; la red es entrenada por una funci&oacute;n de aproximaci&oacute;n (regresi&oacute;n no lineal), patr&oacute;n de asociaci&oacute;n o patr&oacute;n de clasificaci&oacute;n, durante el entrenamiento los pesos y sesgos de la red son iterativamente ajustados para minimizar la funci&oacute;n de desempe&ntilde;o de la red. La funci&oacute;n de desempe&ntilde;o de la red feedforward t&iacute;pica para el entrenamiento de la RNA es el error medio cuadrado (MSE) o suma media del cuadrado de los errores, que se obtiene entre la salida de la red <i>a</i> y el target o valores observados <i>t</i> descrita por la Ecuaci&oacute;n (1):</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e1.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Existen diferentes algoritmos de entrenamiento para las redes feedforward, todos usan el gradiente de la funci&oacute;n de desempe&ntilde;o para determinar c&oacute;mo ajustar los pesos y minimizar el desempe&ntilde;o, el gradiente se determina con una t&eacute;cnica llamada backpropagation, la cual implica llevar a cabo c&aacute;lculos hacia atr&aacute;s a trav&eacute;s de la red. De igual manera existen variaciones de este algoritmo, la implementaci&oacute;n m&aacute;s simple del aprendizaje es actualizar los pesos de la red y los sesgos en la direcci&oacute;n en la cual la funci&oacute;n de desempe&ntilde;o decrece m&aacute;s r&aacute;pidamente, que es el negativo del gradiente, una iteraci&oacute;n de este algoritmo es:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e2.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Donde: <i>w<sub>k</sub>=</i> es el vector de pesos y sesgos actual; <i>g<sub>k</sub>=</i> es el gradiente actual; <i>&alpha;<sub>k</sub>=</i> es la tasa de aprendizaje, y algoritmo m&aacute;s complejo como los de gradiente conjugado, se derivan para incrementar la velocidad de convergencia de esta parte (Demut <i>et al.,</i> 2008).</font></p>  	    <p align="justify"><font face="verdana" size="2">El entrenamiento de la red neuronal puede hacerse m&aacute;s eficiente, si se llevan a cabo ciertos pasos de preprocesamiento sobre las entradas y salidas de la red. Las funciones de preprocesamiento de entrada y salida de la red, transforman dichos datos en una forma m&aacute;s adecuada para el entrenamiento y uso de la red, y la funci&oacute;n reversa regresa las salidas transformadas a las caracter&iacute;sticas de los datos observados originales. Una de estas funciones es el escalamiento de las entradas y salidas de tal forma que &eacute;stas siempre caigan dentro de un rango especifico, por ejemplo de (&#45;1, 1), llamada normalizaci&oacute;n de los datos (Demuth <i>et al.,</i> 2008). Otro preprocesamiento es hacer que caigan dentro de una distribuci&oacute;n normal o alg&uacute;n otro tipo de distribuci&oacute;n estad&iacute;stica como afirma Maier y Dandy (2000).</font></p>  	    <p align="justify"><font face="verdana" size="2">El normalizar los datos resulta un paso esencial para el funcionamiento de la RNA; en algunas situaciones, la dimensi&oacute;n del vector de entradas es muy grande, y los componentes de los vectores est&aacute;n altamente correlacionados (redundantes), es &uacute;til en esta situaci&oacute;n reducir la dimensi&oacute;n del vector de entradas. Un procedimiento para llevar a cabo esta operaci&oacute;n es el an&aacute;lisis de componentes principales, donde se eliminan aquellos componentes que contribuyen con menos a la variaci&oacute;n del conjunto de datos.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Algoritmo backpropagation</b></font></p>  	    <p align="justify"><font face="verdana" size="2">La arquitectura correspondiente para el aprendizaje backpropagation, incorporando ambas fases hacia delante y hacia atr&aacute;s de la computaci&oacute;n implicada en el proceso de aprendizaje, se presenta en la <a href="/img/revistas/remexca/v2n3/a10f1.jpg" target="_blank">Figura 1</a>.</font></p>  	    <p align="justify"><font face="verdana" size="2">La red multicapa en la parte de arriba de la <a href="/img/revistas/remexca/v2n3/a10f1.jpg" target="_blank">Figura 1</a> representa la fase hacia delante. La notaci&oacute;n usada en esta parte es como sigue: <i>w<sup>(l)</sup> =</i> vector de pesos sin&aacute;ptico de una neurona en la capa <i>l</i>; <i>&#952;</i><sup>(l<i>)</i></sup> <i>=</i> umbral de una neurona en la capa <i>l</i>; <i>v</i><sup>(l)</sup> = vector de los niveles de actividad interna de la red de las neuronas en la capa <i>l</i>; <i>y</i><sup>(l<i>)</i></sup> <i>=</i> vector de se&ntilde;ales funci&oacute;n de las neuronas en la capa <i>l</i>.</font></p>  	    <p align="justify"><font face="verdana" size="2">El &iacute;ndice de la capa <i>l</i> incluye desde la capa de entrada (<i>l</i>= 0) a la capa de salida (<i>l</i>= Z); en la <a href="/img/revistas/remexca/v2n3/a10f1.jpg" target="_blank">Figura 1</a> se tiene <i>L=</i> 3; donde <i>L</i> es la profundidad de la red. La parte baja de la <a href="/img/revistas/remexca/v2n3/a10f1.jpg" target="_blank">Figura 1</a> representa la fase hacia atr&aacute;s, la cual es referida como red de sensibilidad para calcular los gradientes locales en el algoritmo backpropagation. La notaci&oacute;n usada en esta segunda parte es como sigue: &#948;<sup>(l)</sup>= vector de gradientes locales de neuronas en la capa <i>l</i>; e= el vector error representado por <i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, ..., <i>e<sub>q</sub></i> como elementos <i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, ...<i>x</i><sub>p</sub>= variables de entrada; <img src="/img/revistas/remexca/v2n3/a10s1.jpg">(&bull;)= funci&oacute;n de activaci&oacute;n.</font></p>  	    <p align="justify"><font face="verdana" size="2">Mientras que la red de la <a href="/img/revistas/remexca/v2n3/a10f1.jpg" target="_blank">Figura 1</a> es meramente una capa de la arquitectura del algoritmo backpropagation, se encuentra que tiene ventajas substanciales en situaciones din&aacute;micas, donde la representaci&oacute;n algor&iacute;tmica comienza a ser voluminosa (Narendra and Parthasarathy, 1990). La actualizaci&oacute;n de pesos patr&oacute;n por patr&oacute;n es el m&eacute;todo preferido para la implementaci&oacute;n en l&iacute;nea del algoritmo backpropagation. Para este modo de operaci&oacute;n, el algoritmo cicla a trav&eacute;s de los datos de entrenamiento &#123;&#91;x(<i>n</i>),d(<i>n</i>)&#93;; <i>n</i> = 1, 2, ..., <i>N</i>&#125; como sigue:</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Inicializaci&oacute;n.</b> Empieza con una configuraci&oacute;n de red razonable, y coloca todos los pesos sin&aacute;pticos y niveles de umbral de la red, para peque&ntilde;os n&uacute;meros aleatorios que est&aacute;n uniformemente distribuidos.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Presentaci&oacute;n de ejemplos de entrenamiento.</b> Presenta la red con una &eacute;poca de ejemplos de entrenamiento. Para cada ejemplo en el conjunto ordenado en alguna forma, ejecutan la siguiente secuencia de c&aacute;lculos hacia delante y hacia atr&aacute;s bajo los puntos c y d, respectivamente.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>C&aacute;lculos hacia delante.</b> Sea un ejemplo de entrenamiento en la &eacute;poca denotado por &#91;x(<i>n</i>), d(<i>n</i>)&#93;, con el vector de entrada x(<i>n</i>) aplicados a la capa de entrada de los nodos sensores y el vector de respuestas deseado d(<i>n</i>), presentado a la capa de salida de los nodos computados. Calcule los potenciales de activaci&oacute;n y las se&ntilde;ales funci&oacute;n de la red procediendo hacia delante a trav&eacute;s de la red, capa por capa. El nivel de actividad interno de la red <i>v</i> <sup>(</sup><i><sub>j</sub><sup>l</sup></i><sup>)</sup>(n) para la neurona <i>j</i> en la capa <i>l</i> es:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e3.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Donde: <i>y</i> <sup>(</sup><i><sub>i</sub><sup>l</sup></i> <sup>&#45;1)</sup> (<i>n</i>) = se&ntilde;al funci&oacute;n de la neurona i en la capa previa <i>l</i> &#45; 1 en la iteraci&oacute;n <i>n</i>; <i>w</i> <sup>(</sup><i><sub>j</sub><sub>i</sub><sup>l</sup></i> <sup>)</sup>(<i>n</i>) = peso sin&aacute;ptico de la neurona <i>j</i> en la capa <i>l</i> que es alimentado de la neurona <i>i</i> en la capa <i>l</i> &#45; 1. Para <i>i</i> = 0, se tiene <i>y</i><sub>0</sub><sup>(<i>l</i></sup> <sup>&#45;1)</sup> (<i>n</i>)= &#45;1 y <i>w</i> <sup>(</sup><i><sub>j</sub><sup>l</sup></i><sub>0</sub><sup>)</sup> (<i>n</i>)= &#952; <sup>(</sup><i><sub>j</sub><sup>l</sup></i><sup>)</sup> (<i>n</i>); donde: <i>&#952;</i> <sup>(</sup><i><sub>j</sub><sup>l</sup></i><sup>)</sup> (<i>n</i>)= umbral aplicado a la neurona <i>j</i> en la capa <i>l</i>. Suponiendo el uso de una funci&oacute;n log&iacute;stica para la no linealidad sigmoidea, la funci&oacute;n se&ntilde;al (salida) de la neurona <i>j</i> en la capa <i>l</i> es:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e4.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Si la neurona <i>j</i> est&aacute; en la primera capa oculta (esto es, <i>l</i> = 1), se coloca:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e5.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Donde: <i>x<sub>j</sub></i>(<i>n</i>)= <i>j</i>&#45;&eacute;simo elemento del vector de entradas <i>x</i>(<i>n</i>). Si la neurona <i>j</i> est&aacute; en la capa de salida (esto es <i>l</i> = <i>L</i>), se coloca:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e6.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">De aqu&iacute;, se calcula la se&ntilde;al de error:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e7.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Donde: <i>d.(n)= j</i>&#45;&eacute;simo elemento de el vector de respuestas deseado d(<i>n</i>), <i>o<sub>j</sub>(n)</i> es la <i>j</i>&#45;&eacute;sima salida de la red.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Computo hacia atr&aacute;s.</b> Calcular los &#948;'s (gradientes locales) de la red procediendo hacia atr&aacute;s, capa por capa; para la neurona/ en la capa de salida <i>L</i> se tiene:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e8.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Para la neurona <i>j</i> en la capa oculta <i>l</i>:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e9.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">De aqu&iacute;, se ajustan los pesos sin&aacute;pticos de la red en la capa <i>l</i> de acuerdo a la regla delta generalizada:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e10.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Donde: <i>&#951;=</i> par&aacute;metro tasa de aprendizaje y <i>&alpha;</i> es la constante momento.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Iteraci&oacute;n.</b> Iteraci&oacute;n de la computaci&oacute;n presentando nuevas &eacute;pocas de entrenamiento a la red, hasta que los par&aacute;metros libres de la red estabilicen sus valores y el error medio cuadrado &#949;<sub>av</sub> calculado sobre el conjunto entero de entrenamiento est&eacute; en el m&iacute;nimo o un valor peque&ntilde;o aceptable. El orden de presentaci&oacute;n de los ejemplos de entrenamiento deber&iacute;a aleatorizarse de &eacute;poca en &eacute;poca. El momento y el par&aacute;metro tasa de aprendizaje son ajustados t&iacute;picamente (usualmente decrecen) tanto como el n&uacute;mero de iteraciones de entrenamiento se incrementan (Haykin, 1994).</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Similitudes y diferencias entre los modelos estad&iacute;sticos tradicionales y las redes neuronales artificiales</b></font></p>  	    <p align="justify"><font face="verdana" size="2">La diferencia entre las t&eacute;cnicas de inteligencia artificial (IA) y la estad&iacute;stica tradicional no es de clase pero si de grado afirma Marzban (2009). Se dice que la mayor&iacute;a de las t&eacute;cnicas pertenecen a un continuo, y diferentes t&eacute;cnicas tienen diferentes grados de pertenencia ya sea a la inteligencia artificial o a la estad&iacute;stica (Marzban, 2009).</font></p>  	    <p align="justify"><font face="verdana" size="2">La comparaci&oacute;n de las redes neuronales artificiales con la parte estad&iacute;stica y espec&iacute;ficamente con las series de tiempo ha originado diversos estudios y actividades (Hill <i>et al.,</i> 1994; Hsieh y Tang, 1998). Marzban (2009) afirma que las redes neuronales son otra herramienta de regresi&oacute;n y clasificaci&oacute;n, y acerca del modelo multicapa perceptr&oacute;n, en t&eacute;rminos de una ecuaci&oacute;n, este es simplemente una generalizaci&oacute;n de la ecuaci&oacute;n de regresi&oacute;n: <i>y = &alpha; + &#946;<sub>i</sub>x<sub>i</sub> + &#946;<sub>z</sub>x<sub>2</sub> +</i> ... <i>+ &#946;<sub>p</sub>x<sub>p</sub> = &alpha; +<img src="/img/revistas/remexca/v2n3/a10s2.jpg"></i>. Los t&eacute;rminos <i>&#952;</i> y <i>&#969;</i> (ecuaci&oacute;n 11) son an&aacute;logos a <i>&alpha;</i> y <i>P</i> en la ecuaci&oacute;n de regresi&oacute;n, siendo los par&aacute;metros de la red:</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e11.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">La representaci&oacute;n que es an&aacute;loga a la Ecuaci&oacute;n 11 se muestra en la <a href="#f2">Figura 2</a>, esta red es referida como multicapa perceptr&oacute;n, con <i>N<sub>in</sub></i> nodos de entrada (<i>x</i><sub>i</sub>), un nodo de salida (<i>y</i>) y una capas oculta de pesos o equivalentemente una capa oculta de nodos <i>(h<sub>t</sub>)</i> donde <i>H es</i> el n&uacute;mero de nodos ocultos y &eacute;ste juega el rol del orden de la regresi&oacute;n polinomial. En la ecuaci&oacute;n 11 <i>f(x)</i> y <i>g(x)</i> son las llamadas funciones de activaci&oacute;n, funciones preespecificadas, su trabajo es transformar los predictores <i>x</i><sub>j</sub>.</font></p>  	    <p align="center"><font face="verdana" size="2"><a name="f2"></a></font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10f2.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Demuth <i>et al.</i> (2008) indican que dos elecciones comunes de estas funciones son <i>tanh(x) =</i> 2/(1+<i>e</i>(&#45;2*<i>x</i>))&#45;1 y <i>logsig(x) = 1/(1 +e<sup>&#45;x</sup>).</i> Marzban (2009) indican tambi&eacute;n que es an&aacute;loga a una serie de Fourier; es decir, una serie de tiempo puede ser escrita como una suma de un conjunto de senos y cosenos (serie de Fourier). La analog&iacute;a con el perceptr&oacute;n multicapa es que cualquier funci&oacute;n es escrita como una combinaci&oacute;n lineal de un conjunto de funciones sigmoideas (Marzban, 2009):</font></p>  	    <p align="center"><font face="verdana" size="2"><img src="/img/revistas/remexca/v2n3/a10e12.jpg"></font></p>  	    <p align="justify"><font face="verdana" size="2">Con respecto al procesamiento de los datos que se realiza en la estad&iacute;stica, especif&iacute;camente con las series de tiempo y comprar&aacute;ndalo con las RNA, la mayor&iacute;a de las series de tiempo exhiben variaciones de tendencia y estacionalidad, la estacionalidad es un patr&oacute;n peri&oacute;dico y recurrente causado por diversos factores, (Zhang y Qi, 2005). Los planteamientos tradicionales para modelar series de tiempo remueven las variaciones estacionales como lo realiza el m&eacute;todo cl&aacute;sico de descomposici&oacute;n que primero, descompone la serie de tiempo en tendencia, estacionalidad, componentes ciclos e irregulares y remueve dichos componentes, as&iacute; como se realizan ciertas actividades en una serie de datos para aplicar el modelo de series de tiempo, existe discusi&oacute;n, sobre si antes de aplicar el modelo de RNA, se debe quitar estacionalidad y tendencia a los datos, priori al entrenamiento para realizar un pron&oacute;stico de mejor ajuste. Zhang y Qi, (2005) afirman con sus resultados que las RNA no son capaces directamente de modelar la estacionalidad, y es deseable remover este componente de los datos antes del entrenamiento para obtener mejor desempe&ntilde;o.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Aplicaciones de las RNA en la estimaci&oacute;n de la evapotranspiraci&oacute;n de referencia y variables meteorol&oacute;gicas relacionadas</b></font></p>  	    <p align="justify"><font face="verdana" size="2">Entre los servicios que proporciona una estaci&oacute;n meteorol&oacute;gica est&aacute;n los predicciones de corto periodo de lluvias para pronostico de inundaciones y operaciones de suministro de agua, pron&oacute;sticos estacionales para sequ&iacute;a y aplicaciones en la agricultura, &eacute;stos se han hecho con modelos num&eacute;ricos, que t&iacute;picamente resuelven ecuaciones tridimensionales para conservaci&oacute;n de masa, momento y energ&iacute;a en la atm&oacute;sfera y como Schoof and Prior (2001) afirman el pron&oacute;stico de rendimientos futuros en la agricultura requiere explicita atenci&oacute;n a la variabilidad clim&aacute;tica.</font></p>  	    <p align="justify"><font face="verdana" size="2">Otro tipo de modelo para pron&oacute;stico es las redes neuronales artificiales, objeto de estudio de este trabajo. Entre los diversos trabajos de investigaci&oacute;n que se han hecho para resolver problemas que tienen que ver con la meteorolog&iacute;a en el campo de la agricultura con redes neuronales, existen los trabajos para pron&oacute;stico y estimaci&oacute;n de temperaturas, radiaci&oacute;n global, humedad relativa, presi&oacute;n real de vapor de agua y evapotranspiraci&oacute;n de referencia.</font></p>  	    <p align="justify"><font face="verdana" size="2">Conocer la humedad relativa resulta importante para el control de enfermedades en los cultivos, en las operaciones poscosecha en almacenamiento y en el transporte de los productos agr&iacute;colas; por ejemplo, en las c&aacute;maras de atm&oacute;sferas controladas se supone que la humedad relativa sea alta (Corrales <i>et al</i>., 1991), esta variable se encuentra ligada a la presi&oacute;n real de vapor de agua, importante como par&aacute;metro de entrada en la modelaci&oacute;n de cultivos. La radiaci&oacute;n global es fuente de energ&iacute;a principal en muchos procesos f&iacute;sicos y bioqu&iacute;micos (uno de estos procesos es la evapotranspiraci&oacute;n) que se llevan a cabo sobre la tierra (Meza and Varas, 2000; Podest&aacute; <i>et al</i>., 2004).</font></p>  	    <p align="justify"><font face="verdana" size="2">En el desarrollo del presente trabajo se encontraron diversos trabajos con RNA para estimar la ET<sub>0</sub>, as&iacute; tambi&eacute;n como las variables necesarias para su c&aacute;lculo, de acuerdo con el bolet&iacute;n 56 de FAO (Allen <i>et al</i>., 1998), s&oacute;lo algunos de estos trabajos se muestran en el <a href="/img/revistas/remexca/v2n3/a10c1.jpg" target="_blank">Cuadro 1</a>; se puede observar que una de las arquitecturas de RNA m&aacute;s com&uacute;nmente usada es la multicapa feedforward backpropagation, m&aacute;s usada aun que la recurrente o Hopfeld; las funciones de transferencia que se han usado, porque han dado buenos resultados en la estimaci&oacute;n de la ET<sub>0</sub>, es la funci&oacute;n sigmoidea, la log&iacute;stica sigmoidea y la radial basis function; en la estimaci&oacute;n de la radiaci&oacute;n global ha dado buenos resultados estas mismas funciones de transferencia, y en la estimaci&oacute;n de la temperatura ha funcionado la sigmoidea y la funci&oacute;n gaussiana, hay que destacar que algunos autores no reportan la funci&oacute;n que usaron.</font></p>  	    <p align="justify"><font face="verdana" size="2">La estimaci&oacute;n que se ha hecho para las diferentes variables ha sido a nivel mensual, diario, horario y a 5 y 10 min probando la capacidad de pron&oacute;stico de las RNA. Finalmente entre los &iacute;ndices estad&iacute;sticos que se han usado para evaluar el desempe&ntilde;o de las RNA, se encontraron que las m&aacute;s comunes son la ra&iacute;z cuadrada del cuadrado medio del error o error promedio (RMSE) y el coeficiente de determinaci&oacute;n (R<sup>2</sup>), siguen en orden de importancia, el error medio sesgado (MBE), el porcentaje de error medio absoluto (MAPE) y el error cuadrado medio (MSE); los menos comunes son el error relativo, error absoluto y coeficiente de variaci&oacute;n. Se observa que por ejemplo, en el campo de la humedad relativa no existen muchos trabajos para estimarla con RNA, de igual forma sucede con la presi&oacute;n real de vapor de agua, y con la velocidad del viento.</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>Perspectivas de las RNA en la predicci&oacute;n de variables agroclim&aacute;ticas</b></font></p>  	    <p align="justify"><font face="verdana" size="2">En el presente la red neuronal multicapa est&aacute;tica todav&iacute;a es el sistema de modelado y m&eacute;todo de predicci&oacute;n popular en las aplicaciones para estimar variables agrometeorol&oacute;gicas y otras. Usar la red neuronal multicapa forward est&aacute;tica para establecer un modelo entrada/salida, esencialmente es conocer la posici&oacute;n de la funci&oacute;n no lineal en el sistema de ecuaciones diferenciales basado en el aprendizaje de la habilidad propuesta de la red. La red neuronal multicapa forward puede obtener buenos resultados en la predicci&oacute;n de la modelaci&oacute;n de sistemas est&aacute;ticos.</font></p>  	    <p align="justify"><font face="verdana" size="2">En la pr&aacute;ctica el sistema que necesita ser modelado y predicho, la mayor&iacute;a de las veces es un sistema din&aacute;mico no lineal variable en el tiempo, y donde no se conoce la posici&oacute;n de la funci&oacute;n no lineal entonces usar la red din&aacute;mica feedback, para continuar el modelado y predicci&oacute;n del sistema puede ser la soluci&oacute;n, y se toma en serio en la aplicaci&oacute;n pr&aacute;ctica, esto representa la tendencia en la modelaci&oacute;n de redes neuronales y predicci&oacute;n. Esto es principalmente debido a que la red din&aacute;mica en s&iacute; misma, es un sistema din&aacute;mico variante en el tiempo, referente al modelado del sistema din&aacute;mico, &eacute;ste tiene la habilidad natural para reflejar el cambio en la din&aacute;mica del sistema, y &eacute;ste no necesita ubicar el tipo y el orden del modelo del sistema por adelantado (Ding <i>et al</i>., 2008).</font></p>  	    <p align="justify"><font face="verdana" size="2">La investigaci&oacute;n actualmente en RNA principalmente se hace en mejoramientos sobre la base del modelo, &eacute;stos se engloban en cuatro aspectos: selecci&oacute;n de par&aacute;metros, algoritmos, funci&oacute;n de activaci&oacute;n y estructura de la red. Los algoritmos de optimizaci&oacute;n pueden ser de gradiente conjugado, Quasi&#45;Newton, Levenberg&#45;Marquardt, entre otros; no obstante, estos algoritmos mejoran la velocidad de convergencia de la red, ellos desperdician espacio de almacenamiento, entonces la investigaci&oacute;n tambi&eacute;n est&aacute; encaminada a la mejora de los algoritmos para no desperdiciar dicho espacio de almacenamiento (Ding <i>et al</i>., 2008).</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>CONCLUSIONES</b></font></p>  	    <p align="justify"><font face="verdana" size="2">Las redes neuronales tienen un amplio prospecto de desarrollo junto con el progreso de la teor&iacute;a b&aacute;sica y la madurez, tanto de la tecnolog&iacute;a inform&aacute;tica como el desarrollo te&oacute;rico de las redes neuronales. Las aplicaciones con RNA, ir&aacute;n extendi&eacute;ndose cada vez m&aacute;s en el campo de la agrometeorolog&iacute;a. Se espera un auge en el campo basado sobre la superioridad especial de las redes neuronales, espec&iacute;ficamente del tipo din&aacute;mico en el procesamiento de problemas no lineales, como la ET<sub>0</sub> y variables asociadas.</font></p>  	    <p align="justify"><font face="verdana" size="2">La comparaci&oacute;n del preprocesamiento de los datos para pron&oacute;stico con RNA y con modelos de serie de tiempo, muestra que ambos tipos de pron&oacute;stico necesitan previamente procesar los datos, y al modelar con una red neuronal artificial, se requiere renovar el componente de estacionalidad y tendencia, para la exactitud del pron&oacute;stico.</font></p>  	    <p align="justify"><font face="verdana" size="2">En el campo de las variables clim&aacute;ticas aplicadas a la agricultura, es donde se vislumbra el futuro que seguir&aacute; la investigaci&oacute;n, con aplicaciones de redes neuronales artificiales en forma din&aacute;mica.</font></p>  	    <p align="justify"><font face="verdana" size="2">&nbsp;</font></p>  	    <p align="justify"><font face="verdana" size="2"><b>LITERATURA CITADA</b></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Alawi, S. M. and Hinai, H. A. 1998. An ANN&#45;based approach for predicting global radiation in locations with no direct measurements instrumentation. Renewable Energy. (14):199&#45;204.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159842&pid=S2007-0934201100030001000001&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Allen, R. G.; Pereira, S. L.; Raes, D. and Smith, M. 1998. Crop evapotranspiration guidelines for computing crop water requirements. FAO Irrigation and drainage paper 56. Roma. 29&#45;86 pp.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159844&pid=S2007-0934201100030001000002&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Benghanem, M.; Mellit, A. and Alamri, S. N. 2009. ANN&#45;based modeling and estimation of daily global solar radiation data: A case study. Energy Conversion Manage. (50):1644&#45;1655.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159846&pid=S2007-0934201100030001000003&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Chauhan, S. and Shrivastava, R. K. 2009. Performance evaluation of reference evapotranspiration estimation using climate based methods and artificial neural networks. Water Resour. Manage. (23):825&#45;837.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159848&pid=S2007-0934201100030001000004&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Chevalier, R. F.; Hoogenboom, G.; McClendon, R. W. and Paz, J. A. 2010. Support vector regression with reduced training sets for air temperature prediction: a comparison with artificial neural networks. Neural computing &amp; applications.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159850&pid=S2007-0934201100030001000005&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Corrales, G. J. E.; Hern&aacute;ndez, M. J. y G&oacute;mez, V. R. 1991. Uso comercial de las atm&oacute;sferas controladas en M&eacute;xico. Universidad Aut&oacute;noma Chapingo. FIRA&#45;Banco de M&eacute;xico. 51 p.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159852&pid=S2007-0934201100030001000006&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Demuth, H.; Beale, M. and Hagan, M. 2008. Neural network toolbooxTM 6. User's guide. 907 p.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159854&pid=S2007-0934201100030001000007&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Ding, S.; Jia, W.; Su, Ch.; Zhang, L. and Shi, Z. 2008. Neural network research progress and applications in forecast. <i>In</i>: Sun <i>et al</i>., (eds.). Springer &#45;Verlag Berlin Heidelberg. 783&#45;793 pp.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159856&pid=S2007-0934201100030001000008&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Elizondo, D.; Hoogenboom, G. and McClendon, R.W. 1994. Development of a neural network model to predict daily solar radiation. Agric. For. Meteorol. (71):115&#45;132.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159858&pid=S2007-0934201100030001000009&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Elminir, H. K.; Areed, F. F. and Elsayed, T. S. 2005. Estimation of solar radiation components incident on Helwan site using neural networks. Sol. Energy. (79):270&#45;279.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159860&pid=S2007-0934201100030001000010&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Gonz&aacute;lez&#45;Camacho, J. M.; Cervantes&#45;Osornio, R.; Bustamante&#45;Ojeda, W. y L&oacute;pez&#45;Cruz, I. L. 2008. Predicci&oacute;n de la evapotranspiraci&oacute;n de referencia mediante redes neuronales artificiales. Ingenier&iacute;a hidr&aacute;ulica en M&eacute;xico. (23):127&#45;138.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159862&pid=S2007-0934201100030001000011&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Haykin, S. S. 1994. Neural Networks. A comprehensive foundation. MacMaster MacMillan Publishing Company, University, Hamilton, Ontario Canada. 696 p.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159864&pid=S2007-0934201100030001000012&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Hill, T.; Marquez, L.; O'Connor, M. and Remus, W. 1994. Artificial neural network models for forecasting and decision making. Int. J. forecasting. (10):5&#45;15</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159866&pid=S2007-0934201100030001000013&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --><!-- ref --><p align="justify"><font face="verdana" size="2">Hsieh, W. W. and Tang, B. 1998. Applying neural network models to prediction and data analysis in meteorology and oceanography. Bulletin of the American Meteorological Society. 9(79):1855&#45;1870.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159867&pid=S2007-0934201100030001000014&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Khoob, A. R. 2008. Comparative study of Hargreave's and artificial neural network's methodologies in estimating reference evapotranspiration in a semiarid environment. Irrig. Sci. (26):253&#45;259.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159869&pid=S2007-0934201100030001000015&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Kim, S. and Kim, H. S. 2008. Neural networks and genetic algorithm approach for nonlinear evaporation and evapotranspiration modeling. J. hydrol. (351):299&#45;317.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159871&pid=S2007-0934201100030001000016&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Kumar, M.; Raghuwanshi, N. S.; Singh, R.; Wallender, W. W. and Pruitt, W. O. 2002. Estimating evapotranspiration using artificial neural network. J. Irrig. drainage eng. (128):224&#45;233.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159873&pid=S2007-0934201100030001000017&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Kumar, M.; Bandyopadhyay, A.; Raghuwanshi, N. S. and Singh, R. 2008. Comparative study of conventional and artificial neural network&#45;based ET<sub>0</sub> estimation models. Irrig. Sci., (26):531:545.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159875&pid=S2007-0934201100030001000018&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Lam, J. C. K.; Wan, K. W. and Yang, L. 2008 Solar radiation modeling using ANNs for different climates in China. Energy conversion and management. (49):1080&#45;1090.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159877&pid=S2007-0934201100030001000019&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Landeras, G.; Ortiz&#45;Barredo, A. and Lopez, J. J. 2008. Comparison of artificial neural network models and empirical and semi&#45;empirical equations for daily reference evapotranspiration estimation in the Basque Country (Northern Spain). Agric. Water Manage. (95):553&#45;565.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159879&pid=S2007-0934201100030001000020&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Lopez, G.; Rubio, M. A.; Martinez, M. and Batles, F. J. 2001. Estimation of hourly gloal photosynthetically active radiation using artificial neural network models. Agric. For. Meteorol. (107):279&#45;291.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159881&pid=S2007-0934201100030001000021&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Maier, H. R. M. and Dandy, C. G. 2000. Neural networks for the prediction and forecasting of water resources variables: a review of modeling issues and applications. Environmental Modelling &amp; Software. (15):101&#45;124.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159883&pid=S2007-0934201100030001000022&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Maqsood, I.; Khan, M. R. and Abraham, A. 2004. An ensemble of neural networks for weather forecasting. Neural Comput &amp; Applic. (13):112&#45;122</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159885&pid=S2007-0934201100030001000023&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --><!-- ref --><p align="justify"><font face="verdana" size="2">Marzban, C. 2009. Basic statistics and basic AI: Neural networks. Artificial Intelligence methods in the environmental sciences. <i>In</i>: Haupt S. E. <i>et al</i>. (eds.). Springer&#45;Verlag Berlin Heidelberg. 15&#45;47 pp.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159886&pid=S2007-0934201100030001000024&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">McCulloch, W. S. and Pitts, W. 1943. A logical calculus of the ideas imminent in nervous activity. Bulletin and Mathematical Biophysics. (5):115&#45;133.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159888&pid=S2007-0934201100030001000025&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Meza, F. and Varas, E. 2000. Estimation of mean monthly solar global radiation as a function of temperature. Agric. For. Meteorol. (100):231&#45;241.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159890&pid=S2007-0934201100030001000026&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Mittal, G. S. and Zhang, J. 2003 Artificial neural network&#45;based psychrometric predictor. Biosystems Eng. (85):283&#45;289.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159892&pid=S2007-0934201100030001000027&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Mohandes, M.; Balghonaim, A.; Kassas, M.; Rehman, S. and Halawani, T. O. 2000. Use of radial basis functions for estimating monthly mean daily solar radiation. Solar Energy. (68):161&#45;168.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159894&pid=S2007-0934201100030001000028&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Mohandes, M.; Rehman, S. and Halawani, T. O. 1998. Estimation of global solar radiation using artificial neural networks. Renewable energy. (14):179&#45;184.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159896&pid=S2007-0934201100030001000029&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Narendra, K. S. and Parthasarathy, K. 1990. Identification and control of dynamical systems using neural networks. IEEE Transactions on Neural Networks. (1):4&#45;27.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159898&pid=S2007-0934201100030001000030&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Podest&aacute;, G. P.; Nu&ntilde;ez, L.; Villanueva, C. A. and Skansi, M. A. 2004. Estimating daily solar radiation in the Argentine Pampas. Agric. For. Meteorol. (123):41&#45;53.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159900&pid=S2007-0934201100030001000031&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Rehman, S. and Mohandes, M. 2008. Artificial neural network estimation of global solar radiation using air temperature and relative humidity. Energy Policy. (36):571&#45;576.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159902&pid=S2007-0934201100030001000032&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Rumelhart, D. E.; Hinton, G. E. and Williams, R. J. 1986. Learning internal representations by error propagation. <i>In</i>: Rumelhart D. E. and McClelland J. L. (eds.). Parallel Distributed Processing. MIT Press, Cambridge. 1&#45;33 pp.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159904&pid=S2007-0934201100030001000033&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Salazar, R.; Schmidt, U.; Huber, C.; Rojano, A. and Lopez, I. 2010. Neural netwokds models for temperature and CO<sub>2</sub> control. Int. J. Agric. Res. 4(5):191&#45;200.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159906&pid=S2007-0934201100030001000034&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Schoof, J. T. and Pryor, S. C. 2001. Downscaling temperature and precipitation: a comparison of regression&#45;based methods and artificial neural networks. Int. J. Clim. (21):773&#45;790</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159908&pid=S2007-0934201100030001000035&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --><!-- ref --><p align="justify"><font face="verdana" size="2">Sfetsos, A. and Coonick, A. H. 2000. Univariate and multivariate forecasting of hourly solar radiation with artificial intelligence techniques. Sol Energy. (68):169&#45;178.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159909&pid=S2007-0934201100030001000036&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Shank, D. B.; Hoogenboom, G. and McClendon, R. W. 2008a. Dew point temperature prediction using artificial neural networks. J. Appl. Meteorol. Clim. (47):1757&#45;1769.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159911&pid=S2007-0934201100030001000037&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Shank, D. B.; McClendon, R. W.; Paz, J. and Hoogenboom, G. 2008b. Ensemble artificial neural networks for prediction of dew point temperature. Appl. Artificial Intelligence. (22):523&#45;542.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159913&pid=S2007-0934201100030001000038&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Sudheer, K. P.; Gosain, A. K. and Ramasastri, K. S. 2003. Estimating actual evapotranspiration from limited climatic data using neural computing technique. J. Irrig. Drainage Eng. (129):214&#45;218.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159915&pid=S2007-0934201100030001000039&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Trajnovic, S.; Todorovic, B. and Stankovic, M. 2003. Forecasting of reference evapotranspiration by artificial neural networks. J. Irrig. Drainage Eng. ASCE. (129):454&#45;457.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159917&pid=S2007-0934201100030001000040&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Wang, Y.; Traore, S. and Kerh, T. 2008. Neural network approach for estimating reference evapotranspiration from limited climatic data in Burkina Faso. Wseas Tansactions on Computers. (7):704&#45;713.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159919&pid=S2007-0934201100030001000041&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Zhang, G.; Patuwo, E. B. and Hu, Y. M. 1998. Forecasting with artificial neural networks: the state of the art. Int. J. Forecasting. (14):35&#45;62.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159921&pid=S2007-0934201100030001000042&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>  	    <!-- ref --><p align="justify"><font face="verdana" size="2">Zhang, G. P. and Qi, M. 2005. Neural network forecasting for seasonal and trend time series. European J. Operational Res. (160):501&#45;514.    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&#160;<a href="javascript:void(0);" onclick="javascript: window.open('/scielo.php?script=sci_nlinks&ref=6159923&pid=S2007-0934201100030001000043&lng=es','','width=640,height=500,resizable=yes,scrollbars=1,menubar=yes,');">Links</a>&#160;]<!-- end-ref --></font></p>      </div></div><!--cc--><!--mode=license--><!--GENERAL_LICENSE--><div xmlns="" class="license"><p><a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.es"><img src="http://i.creativecommons.org/l/by-nc/3.0/80x15.png" alt="Creative Commons License" style="border-width:0"></a> <!--issue-->Todo el contenido de esta revista, excepto dónde está identificado, está bajo una <a href="http://creativecommons.org/licenses/by-nc/3.0/deed.es">Licencia Creative Commons</a></p></div>
<div xmlns="" class="footer">Campo Experimental Valle de México, Km13.5, Carretera Los Reyes-Lechería, Colonia Coatlinchán, Texcoco, Estado de México, MX, 56250, (52-595) 92 12681<br><IMG src="/img/es/e-mailt.gif" border="0"><br><A class="email" href="mailto:revista_atm@yahoo.com.mx">revista_atm@yahoo.com.mx</A><script type="text/javascript">
              var _gaq = _gaq || [];
              _gaq.push(['_setAccount', 'UA-25452014-1']);
              _gaq.push(['_trackPageview']);
              _gaq.push(['_setSampleRate', '']);

              (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
              })();

            </script>
</div></div></body></html>
<!--transformed by PHP 12:04:20 04-04-2019-->
<!--CACHE MSG: CACHE NAO FOI UTILIZADO -->
<!-- REQUEST URI: /scielo.php?script=sci_arttext&pid=S2007-09342011000300010-->
<!--SERVER:132.248.9.5-->